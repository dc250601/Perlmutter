{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import coat\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from typing import Any\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "import PIL.Image as Image\n",
    "import PIL as pil\n",
    "import time\n",
    "import einops\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations.augmentations.transforms import ImageOnlyTransform\n",
    "class restruct(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): The stacked Image .\n",
    "        Returns:\n",
    "            Tensor: Restructured Image into 13 channels.\n",
    "        \"\"\"\n",
    "    \n",
    "        return einops.rearrange(torch.squeeze(img), 'h ( w c ) -> c h w ', w = 125, c=13)\n",
    "\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return auc\n",
    "\n",
    "def straightner(a):\n",
    "    A = np.zeros((a[0].shape[0]*len(a)))\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    for i in range(len(a)):\n",
    "        start_index = i*a[0].shape[0]\n",
    "        end_index = start_index+a[0].shape[0]\n",
    "        A[start_index:end_index] = a[i]\n",
    "    return A\n",
    "\n",
    "def predictor(outputs):\n",
    "    return np.argmax(outputs, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "def pil_loader(path: str) -> Image.Image:\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('L')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "train_transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            restruct(),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.RandomVerticalFlip(),\n",
    "                            transforms.RandomRotation(60),])\n",
    "\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            restruct()])\n",
    "\n",
    "\n",
    "dataset_train = datasets.ImageFolder(\"C:/Users/ML_RTC/Desktop/Tau/data/Tau_Dataset/Train/\",\n",
    "                                    transform =train_transform,\n",
    "                                    loader = pil_loader)\n",
    "\n",
    "dataset_test = datasets.ImageFolder(\"C:/Users/ML_RTC/Desktop/Tau/data/Tau_Dataset/Test/\",\n",
    "                                    transform =test_transform,\n",
    "                                    loader = pil_loader)\n",
    "\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test,\n",
    "                                            batch_size=300,\n",
    "                                            shuffle=True,\n",
    "                                            drop_last = True,\n",
    "                                            num_workers=0,\n",
    "                                            pin_memory = True)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train,\n",
    "                                            batch_size=300,\n",
    "                                            shuffle=True,\n",
    "                                            drop_last = True,\n",
    "                                            num_workers=0,\n",
    "                                            pin_memory = True)\n",
    "\n",
    "\n",
    "image_size = (128,128)\n",
    "in_channels = 13\n",
    "num_blocks = [2, 2, 3, 5, 2]\n",
    "channels = [64, 96, 192, 384, 768]\n",
    "num_classes = 1\n",
    "model = coat.CoAtNet(image_size = image_size,\n",
    "                        in_channels = in_channels,\n",
    "                    num_blocks = num_blocks,\n",
    "                    channels = channels,\n",
    "                    num_classes = num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0005, weight_decay = 0.05)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', verbose = True,threshold = 0.0001,patience = 3, factor = 0.5)\n",
    "\n",
    "checkpoint = torch.load(\"./model_Epoch_49.pt\")\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factor': 0.5,\n",
       " 'min_lrs': [0],\n",
       " 'patience': 3,\n",
       " 'verbose': True,\n",
       " 'cooldown': 0,\n",
       " 'cooldown_counter': 0,\n",
       " 'mode': 'max',\n",
       " 'threshold': 0.0001,\n",
       " 'threshold_mode': 'rel',\n",
       " 'best': -inf,\n",
       " 'num_bad_epochs': 0,\n",
       " 'mode_worse': -inf,\n",
       " 'eps': 1e-08,\n",
       " 'last_epoch': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factor': 0.5,\n",
       " 'min_lrs': [0],\n",
       " 'patience': 3,\n",
       " 'verbose': True,\n",
       " 'cooldown': 0,\n",
       " 'cooldown_counter': 0,\n",
       " 'mode': 'max',\n",
       " 'threshold': 0.0001,\n",
       " 'threshold_mode': 'rel',\n",
       " 'best': 0.871393719131103,\n",
       " 'num_bad_epochs': 0,\n",
       " 'mode_worse': -inf,\n",
       " 'eps': 1e-08,\n",
       " 'last_epoch': 49,\n",
       " '_last_lr': [6.25e-05]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    if param.device.type !=\"cuda\":\n",
    "    \tprint(\"not cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:349s2vbl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">CoAt-0_restart</strong>: <a href=\"https://wandb.ai/dc250601/Tau_Run0/runs/349s2vbl\" target=\"_blank\">https://wandb.ai/dc250601/Tau_Run0/runs/349s2vbl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221102_003201-349s2vbl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:349s2vbl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ML_RTC\\Desktop\\Tau\\Models\\CoAt_Net\\wandb\\run-20221102_003255-hx7yyloj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dc250601/Tau_Run0/runs/hx7yyloj\" target=\"_blank\">CoAt-0_restart</a></strong> to <a href=\"https://wandb.ai/dc250601/Tau_Run0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4316 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m outputs_list\u001b[39m.\u001b[39mappend(outputs\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     39\u001b[0m scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 40\u001b[0m scaler\u001b[39m.\u001b[39;49mstep(optimizer)\n\u001b[0;32m     41\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m     42\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    336\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 338\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    340\u001b[0m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m OptState\u001b[39m.\u001b[39mSTEPPED\n\u001b[0;32m    342\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:285\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39m(v\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m--> 285\u001b[0m     retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    286\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\torch\\optim\\adamw.py:161\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m             max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    159\u001b[0m         state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 161\u001b[0m     adamw(params_with_grad,\n\u001b[0;32m    162\u001b[0m           grads,\n\u001b[0;32m    163\u001b[0m           exp_avgs,\n\u001b[0;32m    164\u001b[0m           exp_avg_sqs,\n\u001b[0;32m    165\u001b[0m           max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m           state_steps,\n\u001b[0;32m    167\u001b[0m           amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    168\u001b[0m           beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    169\u001b[0m           beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    170\u001b[0m           lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    171\u001b[0m           weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    172\u001b[0m           eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    173\u001b[0m           maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    174\u001b[0m           foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    175\u001b[0m           capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\torch\\optim\\adamw.py:218\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 218\u001b[0m func(params,\n\u001b[0;32m    219\u001b[0m      grads,\n\u001b[0;32m    220\u001b[0m      exp_avgs,\n\u001b[0;32m    221\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    222\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    223\u001b[0m      state_steps,\n\u001b[0;32m    224\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    225\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    226\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    227\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    228\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    229\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    230\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    231\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[1;32mc:\\Users\\ML_RTC\\Desktop\\Tau\\work\\lib\\site-packages\\torch\\optim\\adamw.py:266\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    263\u001b[0m param\u001b[39m.\u001b[39mmul_(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m weight_decay)\n\u001b[0;32m    265\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39;49madd_(grad, alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta1)\n\u001b[0;32m    267\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m capturable:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"cb53927c12bd57a0d943d2dedf7881cfcdcc8f09\")\n",
    "wandb.init(\n",
    "    project = \"Tau_Run0\",\n",
    "    name = \"CoAt-0_restart\"\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "#--------------------------\n",
    "wandb.watch(model, log_freq=50)\n",
    "#---------------------------\n",
    "w_intr = 50\n",
    "\n",
    "for epoch in range(50,100):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_steps = 0\n",
    "    test_steps = 0\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    train_auc = 0\n",
    "    test_auc = 0\n",
    "    model.train()\n",
    "    for image, label in tqdm(dataloader_train):\n",
    "        image = image.to(\"cuda\")\n",
    "        label = label.to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            image = nn.functional.pad(image, (2,1,2,1))\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, label.float())\n",
    "        label_list.append(label.detach().cpu().numpy())\n",
    "        outputs_list.append(outputs.detach().cpu().numpy())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        if train_steps%w_intr == 0:\n",
    "                wandb.log({\"loss\": loss.item()})\n",
    "    with torch.no_grad():\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        train_auc = metric(label_list, outputs_list) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm(dataloader_test):\n",
    "            image = image.to(\"cuda\")\n",
    "            image = nn.functional.pad(image, (2,1,2,1))\n",
    "            label = label.to(\"cuda\")\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, label.float())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "            outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            val_loss += loss.item()\n",
    "            test_steps +=1\n",
    "            if test_steps%w_intr == 0:\n",
    "                wandb.log({\"val_loss\": loss.item()})\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        test_auc = metric(label_list, outputs_list)\n",
    "\n",
    "    train_loss = train_loss/train_steps\n",
    "    val_loss = val_loss/ test_steps\n",
    "#     hist_loss_train.append(train_loss)\n",
    "#     hist_loss_test.append(val_loss)\n",
    "#     hist_auc_train.append(train_auc)\n",
    "#     hist_auc_test.append(test_auc)\n",
    "\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Epoch No\" , epoch)\n",
    "    print(\"The Training loss of the epoch, \",train_loss)\n",
    "    print(\"The Training AUC of the epoch,  %.3f\"%train_auc)\n",
    "    print(\"The validation loss of the epoch, \",val_loss)\n",
    "    print(\"The validation AUC of the epoch, %.3f\"%test_auc)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    PATH = f\"model_Epoch_{epoch}.pt\"\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "            }, PATH)\n",
    "    scheduler.step(test_auc)\n",
    "    curr_lr = scheduler._last_lr[0]\n",
    "    wandb.log({\"Train_auc_epoch\": train_auc,\n",
    "                \"Epoch\": epoch,\n",
    "                \"Val_auc_epoch\": test_auc,\n",
    "                \"Train_loss_epoch\": train_loss,\n",
    "                \"Val_loss_epoch\": val_loss,\n",
    "                \"Lr\": curr_lr}\n",
    "                )\n",
    "    gc.collect()\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('work': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a451ac2f6474dd9b0a30794b989a06fd287e54d8f56584134d8b3bcabcab9c76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
